---
typora-root-url: ../../picture
---

**MySQL**



**事务特性**

原子性、一致性、隔离性、持久性

隔离级别:

读未提交（脏读，不可重复读，幻读）、读已提交（解决脏读、还有不可重复读，幻读）、可重复读（解决不可重复读，通过 间隙锁、next-key 锁解决幻读）、序列化 



**InnoDB 默认的隔离级别**

可重复读



**mysql 不同的隔离界别都会有什么问题呢**

读未提交（脏读，不可重复读，幻读）

读已提交（解决脏读、还有不可重复读，幻读）

可重复读（解决不可重复读，InnoDB通过 间隙锁、next-key 锁解决幻读）

序列化 (性能差一点，XA 事物需要使用该级别)



**mysql 不同隔离级别的实现原理**

https://segmentfault.com/a/1190000025156465



**索引 种类，优化方法**

单列：主键 、唯一、前缀 、普通索引

多列：复合索引，遵循最左前缀原则，可以使用覆盖索引优化查询。



内部实现分类：

聚簇索引：主键索引， 叶子节点保存所有的字段



非聚簇索引：叶子节点只保存 索引字段和主键值。 需要根据主键再通过聚簇索引查询一遍，“回表”



自适应性 hash 索引： mysql 内部使用 不对外暴露， 等值查询加速性能



**什么是最左前缀原则**



查询的时候从左起条件精确匹配到第几列，就能用到第几列进行索引查询


 索引不能参与计算，最左侧模糊搜索、使用函数、 如果多列索引里有，则只能只用前面的字段搜索



**为什么有最左前缀原则**

联合索引在磁盘上的结构和声明的顺序是相同的，在等值查询中，只能按索引顺序进行判断，假如一个索引有 （a,b,c）三个字段，那么如果对 a 字段使用函数，就不能保证搜索的目标真的是否是 a ，所以只能全表查询。这样后面的 b,c 也无需在判断了。 所以我们在使用索引的时候需要尽量让索引里的字段根据声明顺序使用等值判断。才可以正常的使用索引。









**锁：**

类型：



按读写分类：共享锁 （SELECT ... LOCK IN SHARE MODE）、排他锁 （SELECT ... FOR UPDATE）



按粒度：按行锁，间隙锁 （RR 级别 解决幻读问题）、next-key 锁，表锁（表锁是意向锁，分为意向共享、意向排他 目的：在树形结构下提高加锁性能，上表锁不用去遍历叶子节点）

意向锁的解释：https://blog.csdn.net/qq_41026740/article/details/97408858



间隙锁：左开右闭 

上锁2原则+2优化+1bug：

原则：基本单位是 next-key 锁，访问到的对象才会加锁。

优化：等值查询 扫描到 唯一索引 数据退化成行锁。

优化：等值查询，向右侧遍历且最后一个值不满足条件的时候， 退化为间隙锁

bug:唯一索引上的范围查询会查询到不满足条件的第一列为止 8.0.13 后有一个版本修复了，但是仅限主键索引，非主键还有)





mdl 锁 （server 层面，ddl 操作相关 ，用于解决或者保证DDL操作与DML操作之间的一致性。） https://www.modb.pro/db/45669 





auto-inc 锁（自增主键）

——————————————————



**MySQL的WAL （Write-Ahead Logging）机制**

WAL 是预写式日志, 关键点在于先写日志再写磁盘.

在对数据页进行修改时, 通过将"修改了什么"这个操作记录在日志中, 而不必马上将更改内容刷新到磁盘上, 从而将随机写转换为顺序写, 提高了性能.

但由此带来的问题是, 内存中的数据页会和磁盘上的数据页内容不一致, 此时将内存中的这种数据页称为 脏页。



**脏页**

当内存数据页和磁盘数据页内容不一致的时候, 将内存页称为"脏页".
 内存数据页写入磁盘后, 两边内容一致, 此时称为"干净页".
 将内存数据页写入磁盘的这个操作叫做"刷脏页"(flush).

InnoDB是以缓冲池(Buffer Pool)来管理内存的, 缓冲池中的内存页有3种状态:

- 未被使用
- 已被使用, 并且是干净页
- 已被使用, 并且是脏页

由于InnoDB的策略通常是尽量使用内存, 因此长时间运行的数据库中的内存页基本都是被使用的, 未被使用的内存页很少.



刷脏页(flush)

时机

刷脏页的时机:

1. Redo Log写满了, 需要将 checkpoint 向前推进, 以便继续写入日志checkpoint 向前推进时, 需要将推进区间涉及的所有脏页刷新到磁盘.
2. 内存不足, 需要淘汰一些内存页(最久未使用的)给别的数据页使用.此时如果是干净页, 则直接拿来复用.
    如果是脏页, 则需要先刷新到磁盘(直接写入磁盘, 不用管Redo Log, 后续Redo Log刷脏页时会判断对应数据页是否已刷新到磁盘), 使之成为干净页再拿来使用.
3. 数据库系统空闲时当然平时忙的时候也会尽量刷脏页.
4. 数据库正常关闭此时需要将所有脏页刷新到磁盘.

InnoDB需要控制脏页比例来避免Redo Log写满以及单次淘汰过多脏页过多的情况.







**mysql 日志类型**

查询、错误、慢查询、binglog\relay log 、undo 、redo



Binlog ：二进制日志（逻辑修改），server 层生成用于 主从复制和数据恢复

格式：row \statement \mixed

row: 对单行的直接修改， 好处：保证数据库一致性、 坏处：量大

statement： 执行语句的复制 ，好处：数据量小  坏处：容易发生主从不一致

Mixed：上面的两中类型折中方案，对一致性没影响的直接复制语句，其他的复制对记录的直接复制row 格式



**1**、**MySQL**的复制原理以及流程

基本原理流程，3个线程以及之间的关联；

主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中；

从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进 自己的relay log中；

从：sql执行线程——执行relay log中的语句；





- [【2】Innnodb 四大特性](https://www.cnblogs.com/gered/p/11911904.html#_label1)

- - [【2.1】插入缓冲（insert buffer)](https://www.cnblogs.com/gered/p/11911904.html#_label1_0)
  - [【2.2】二次写(double write)](https://www.cnblogs.com/gered/p/11911904.html#_label1_1)
  - [【2.3】自适应哈希索引(ahi)](https://www.cnblogs.com/gered/p/11911904.html#_label1_2)
  - 异步 IO
  - 刷新邻接页
  - 预读





————————————

事物的实现基础：

InnoDB 如何实现 AICD

一致性是目的，原子、隔离、持久是手段



答：原子性：undo  隔离性 ：锁+ mvcc + 隔离级别 、 持久性：redo+ undo + 双写buffer

以上三个性质都满足才能满足一致性



**undo log 、redo log**  



Redo log: 提高数据库性能、保证事物的持久性。 

物理格式、Redo日志记录某数据被修改后的值 。记录物理数据页的修改信息， 各个事物穿插按顺序写入。

产生条件：事物开始产生，在事物过程中随即进行写入，根据刷盘配置一般在提交前全部落盘



( 刷盘时机 

innodb_flush_logs_at_trx_commit

​    \1.  日志缓存区将每隔一秒写到日志文件中 write，并且将日志文件的数据刷新到磁盘上 sync。

　　2，每次事务提交时MySQL都会把日志缓存区的数据写入日志文件中，并且刷新到磁盘中 (write+ sync)，该模式为系统默认。

　　3，每次事务提交时MySQL都会把日志缓存区的数据写入日志文件中(write)，但是并不会同时刷新到磁盘上。该模式下，MySQL会每秒执行一次刷新磁盘操作(sync)。



mysql 对数据修改先记录 redo log 然后在内存中修改记录（记录成为脏页 ） 然后后台线程定时将脏页刷洗到磁盘。这个时候如果进程崩溃，则可以在重启的时候根据redo log 重做日式，重做后再执行 undo log（undo log 也记录在 redo 里了，所以只通过 redo log 就能正常恢复）。



Redo 日志 是有限的，通过 check point 和 lsn 机制实现重用和正确的恢复：

CheckPoint 是 mysql 将数据刷盘的位置，通过 lsn 号记录，当发生崩溃的时候只需要将 check point 后的数据进行重做。





lsn:日志序列号，递增 8 字节数字，代表事物写入到日志的总量， redo log 、check point 和 每个数据页都有最后一次修改的 lsn ，用于 恢复的时候根据 LSN 号的大小确认是否要恢复该页。



checkpoint和LSN的工作机制：日志空间中每条日志对应一个 lsn号，检查点和每个数据页头部也有代表最后一次修改的lsn 号，当数据刷盘后，去更新checkpoint,用于减少恢复的记录。 redo log 需要支持觅等性，例子：写 checkpoint 的时候崩溃，检查点前的数据也会 redo ，所以需要幂等性。



undo log ：保证数据库的原子性，用于事物回滚。 还是MVCC 机制的基础。

逻辑日志：保存数据修改前的状态

物理格式：undo存放在数据库内部的一个特殊段（segment）中，这个段称为undo段（undo segment）。另外，**undo log**也会产生redo log，因为**undo log**也要实现持久性保护。





MVCC : 解决读和写的冲突。实现了 快照读的机制，保证了隔离性

当前度： 每次读都是最近的记录， for update \lock in share mode \delete \update \insert 

快照读： select 



原理基础：undo日志 、版本链、read view

原理前提：mysql 正常情况下（有主键） 每条记录包含2 个隐藏字段，1. trx_idx 2. roll_back_pointer 



trx_idx 记录最近一次修改该行的事物ID (begin 的时候分配 递增), roll_back_pointer 指向 undo log 中最近一次修改的版本记录， undo log 中也有trx_id 和 roll_back_pointer 这样，每条记录可以形成一个链表。 在事物读取数据的时候 会生成 read_view 保存当前系统所有相关的事物 id ，最新，最旧 活跃的。



【当前读】的时候，每次生成一个 read_view 数据， 【快照读】只在第一次读生成 ，然后根据事物id 判断可见性

即可实现不同的事物看到不同的版本记录的目标。



**问题：为什么binglog 不能代替 undo log 回滚**

1. 1. Binlog 是mysql 层面的日志， undo \redo 是存储引擎层面的日志 ，实现上innoDB 无法控制
   2.  undo log 可以通过 trx_id，roll_back 指针 记录 每个事物应该回滚的版本， binlog 没法按版本有效回滚，顶多按照时刻去回滚

**问题：为什么binglog 不能代替 redo log**

1.Binlog 是mysql 层面的日志， undo \redo 是存储引擎层面的日志 ，实现上innoDB 无法控制

2.redo 是物理页的改动，binglog 是逻辑改动，在崩溃恢复的时候我们需要基于物理逻辑恢复（逻辑恢复无法保证幂等性）。并且redo log 有 lsn 和 检查点机制 ，有效确定那些物理页已经落盘，那些没落盘需要 重做,从而减少重做时间  bing log 不行





**问题：数据库自增主键用完后，会咋样？**

 直接报错，不会增长了。







**
 sql 语句优化：**

避免全表扫描类：

1. 字段尽量不用 null 值，搜索的时候不用 != 或者 <>  
2. 避免 where 条件里 带有 null 值
3. 一般的时候可以用 exist 代替 in
4. 用 join 代替子查询
5. Group 的时候用 where 子句先过滤大部分后再 having
6. 用索引



优化：

1. 在经常需要搜索、区分度高的列上建立索引
2. 在经常需要使用连接的列上建立索引
3. 经常范围搜索的列
4. 经常需要排序的列
5. 当只要一行数据时使用limit 1，MySQL数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据
6. 使用 ENUM 而不是 VARCHAR。如果你有一个字段，比如“性别”，“国家”，“民族”，“状态”或“部门”，你知道这些字段的取值是有限而且固定的，那么，你应该使用 ENUM 而不是VARCHAR。

不应该加索引：

1. 区分度低
2. 不经常使用
3. text blob 类型：太大了
4. 修改多于查询的时候尽量少加索引

结构优化：

1. 使用 分区表
2. 数据库垂直拆分 指的是按照业务对数据库中的表进行分组，同组的放到一个新的数据库（逻辑上，并非实例）中。
3. 水平拆分，大表变小表 （可能需要注意唯一 ID 的问题）

硬件优化：

升级实例规格





### INNODB 四大特性

1. 插入缓冲

首先对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中。

若在，则直接插入；若不在，则先放入到一个Insert Buffer对象中。

给外部的感觉好像是树已经插入非聚集的索引的叶子节点，而其实是存放在其他位置了

以一定的频率和情况进行Insert Buffer和辅助索引页子节点的merge（合并）操作，通常会将多个插入操作一起进行merge，这就大大的提升了非聚集索引的插入性能。

1. 双写缓冲

为什么需要双写？个人理解宏观上还是与InnoDB需要支持事务（ACID）特性有关，而底层的原因是为了解决Partial Write Page问题。

InnoDB的页大小默认为16K，可以使用参数innodb_page_size设置， 可设置的值有： 64KB，32KB，16KB（默认），8KB和4KB。并且在数据校验时也针对页进行计算，即他们是一个整个对待，包括把数据持久化到磁盘的操作。而计算机的硬件和操作系统在极端情况下（比如断电、系统崩溃）时，刚写入了4K或8K数据，那么就不能保证该操作的原子性，称为部分页面写问题（Partial Write Page）。



1. 自适应hash 索引
2. 预读







### 一、为什么用 自增列 作为主键

1、如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择主键作为聚集索引。

如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引。

如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的)。



2、数据记录本身被存于主索引（一颗B+Tree）的叶子节点上，这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放

因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）

3、如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页

4、如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置

此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销

同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。





### 二、为什么使用数据索引能提高效率

1. 数据索引的存储是有序的
2. 在有序的情况下，通过索引查询一个数据是无需遍历所有记录的
3. 极端情况下，数据索引的查询效率为二分法查询效率，趋近于 log2(N)





### 三、**B+**树索引和哈希索引的区别

B+树是一个平衡的多叉树，从根节点到每个叶子节点的高度差值不超过1，而且同层级的节点间有指针相互链接，是有序的。



哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可,是无序的。

四、哈希索引的优势：

等值查询，哈希索引具有绝对优势（前提是：没有大量重复键值，如果大量重复键值时，哈希索引的效率很低，因为存在所谓的哈希碰撞问题。）



### 五、哈希索引不适用的场景：

1. 不支持范围查询
2. 不支持索引完成排序
3. 不支持联合索引的最左前缀匹配规则

通常，B+树索引结构适用于绝大多数场景，像下面这种场景用哈希索引才更有优势：

在HEAP表中，如果存储的数据重复度很低（也就是说基数很大），对该列数据以等值查询为主，没有范围查询、没有排序的时候，特别适合采用哈希索引，例如这种SQL：

\# 仅等值查询

select id, name from table where name='李明'; 

而常用的 InnoDB 引擎中默认使用的是B+树索引，它会实时监控表上索引的使用情况。

如果认为建立哈希索引可以提高查询效率，则自动在内存中的“自适应哈希索引缓冲区”建立哈希索引（在InnoDB中默认开启自适应哈希索引）。

通过观察搜索模式，MySQL会利用index key的前缀建立哈希索引，如果一个表几乎大部分都在缓冲池中，那么建立一个哈希索引能够加快等值查询。



### 六、**B**树和**B+**树的区别

1、B树，每个节点都存储key和data，所有节点组成这棵树，并且叶子节点指针为null，叶子结点不包含任何关键字信息。

![data](/db/data.jpg)

2、B+树，所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接

所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而B 树的非终节点也包含需要查找的有效信息



B+ 树非叶子节点不存储数据更矮，随机 IO 次数少，并且数据存储在叶子节点通过链表链接，对范围搜索更友好。



七、为什么说**B+**比**B**树更适合实际应用中操作系统的文件索引和数据库索引？



### 1、B+的磁盘读写代价更低。

B+的内部结点并没有指向关键字具体信息的指针，因此其内部结点相对B树更小。

如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。

2、B+-tree的查询效率更加稳定。

由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。

3、B+ 树对范围遍历友好，这个优势很大



**InnoDB 页和索引的关系**

**https://www.cnblogs.com/lnlvinso/p/14655658.html**



### 八、**MySQL**联合索引

1、联合索引是两个或更多个列上的索引。

对于联合索引:Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。

例如索引是key index (a,b,c). 可以支持a 、 a,b 、 a,b,c 3种组合进行查找，但不支持 b,c进行查找 .当最左侧字段是常量引用时，索引就十分有效。

2、利用索引中的附加列，您可以缩小搜索的范围，但使用一个具有两列的索引不同于使用两个单独的索引。

复合索引的结构与电话簿类似，人名由姓和名构成，电话簿首先按姓氏对进行排序，然后按名字对有相同姓氏的人进行排序。

如果您知道姓，电话簿将非常有用；如果您知道姓和名，电话簿则更为有用，但如果您只知道名不知道姓，电话簿将没有用处。



### 十、什么是表分区？

表分区，是指根据一定规则，将数据库中的一张表分解成多个更小的，容易管理的部分。从逻辑上看，只有一张表，但是底层却是由多个物理分区组成。

### 十一、表分区与分表的区别

分表：指的是通过一定规则，将一张表分解成多张不同的表。比如将用户订单记录根据时间成多个表。

分表与分区的区别在于：分区从逻辑上来讲只有一张表，而分表则是将一张表分解成多张表。







### 十一、表分区有什么好处？

1、存储更多数据。分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备。和单个磁盘或者文件系统相比，可以存储更多数据

2、优化查询。在where语句中包含分区条件时，可以只扫描一个或多个分区表来提高查询效率；涉及sum和count语句时，也可以在多个分区上并行处理，最后汇总结果。

3、分区表更容易维护。例如：想批量删除大量数据可以清除整个分区。

4、避免某些特殊的瓶颈，例如InnoDB的单个索引的互斥访问，ext3问价你系统的inode锁竞争等。

十三、分区表的限制因素

1. 一个表最多只能有1024个分区
2. MySQL5.1中，分区表达式必须是整数，或者返回整数的表达式。在MySQL5.5中提供了非整数表达式分区的支持。
3. 如果分区字段中有主键或者唯一索引的列，那么多有主键列和唯一索引列都必须包含进来。即：分区字段要么不包含主键或者索引列，要么包含全部主键和索引列。
4. 分区表中无法使用外键约束
5. MySQL的分区适用于一个表的所有数据和索引，不能只对表数据分区而不对索引分区，也不能只对索引分区而不对表分区，也不能只对表的一部分数据分区。

### 十五、**MySQL**支持的分区类型有哪些？

1. **RANGE**分区： 这种模式允许将数据划分不同范围。例如可以将一个表通过年份划分成若干个分区
2. **LIST**分区： 这种模式允许系统通过预定义的列表的值来对数据进行分割。按照List中的值分区，与RANGE的区别是，range分区的区间范围值是连续的。
3. **HASH**分区 ：这中模式允许通过对表的一个或多个列的Hash Key进行计算，最后通过这个Hash码不同数值对应的数据区域进行分区。例如可以建立一个对表主键进行分区的表。
4. **KEY**分区 ：上面Hash模式的一种延伸，这里的Hash Key是MySQL系统产生的。

十九、行级锁定的优点：

1、当在许多线程中访问不同的行时只存在少量锁定冲突。

2、回滚时只有少量的更改

3、可以长时间锁定单一的行。



### 二十、行级锁定的缺点：

1. 比页级或表级锁定占用更多的内存。 （InnoDB 不是这样）
2. 当在表的大部分中使用时，比页级或表级锁定速度慢，因为你必须获取更多的锁。
3. 如果你在大部分数据上经常进行GROUP BY操作或者必须经常扫描整个表，比其它锁定明显慢很多。
4. 用高级别锁定，通过支持不同的类型锁定，你也可以很容易地调节应用程序，因为其锁成本小于行级锁定。





### 二十二、**key**和**index**的区别

1. key 是数据库的物理结构，它包含两层意义和作用，一是约束（偏重于约束和规范数据库的结构完整性），二是索引（辅助查询用的）。包括primary key, unique key, foreign key 等
2. index是数据库的物理结构，它只是辅助查询的，它创建时会在另外的表空间（mysql中的innodb表空间）以一个类似目录的结构存储。索引要分类的话，分为前缀索引、全文本索引等；



### **MySQL 为什么使用 B+ 树来作索引，对比 B 树它的优点和缺点是什么？**

1.首先进行背景分析：

我们一般的搜索条件有两种，等值或者是范围搜索。

首先，我们加入使用一种线性的数据结构（例如数组）存储信息，那么对于以上两个搜索条件来说时间复杂度是 O(n) ，就算在内存中也是很耗费是时间的。

如果我们想优化搜索时间的话，可以将数据变得有序，使用二分法搜索数据，这样时间复杂度可以降到 O( lgN) ，但是对于插入和删除来说复杂度依然是 O(n) 如果想优化的可以使用链表来存储数据，但是查找就会又变成 O(n) 了。

所以我们希望在 O( lgN) 不变的条件下插入时间复杂度更少的数据结构，就是树。树的种类有很多在这里比较合适的有，二叉搜索树，B- 树。 他俩的结构差不多，但是B- 树的节点可以存储一个范围的数据，整体上 B- 树的层高更矮，所以我们优先选择B-树。现在我们可以在查询时间复杂度为 O( lgN) 同时保证插入的复杂度尽量低。但是对于B -树来说范围搜索确成了问题，它需要到不同的节点去取数据，随机IO 太多，所以我们目前需要优化范围搜索的问题。

我们又找到了B+ 树，他是B- 树的升级版本，非叶子节点不存储数据，只存储索引。数据在叶子节点上并且通过链表前后相连接。这样很容易的满足了范围搜索的空间局部性优势，减少随机IO。并且由于数据只在叶子节点上，B+ 树的层高整体比B- 树更矮。所以它最适合做数据库的索引。









### **什么是数据库事物 ,MySQL 为什么会使用 InnoDB 作为默认选项** 

事务其实就是并发控制的基本单位；相信我们都知道，事务是一个序列操作，其中的操作要么都执行，要么都不执行，它是一个不可分割的工作单位；数据库事务的 ACID 四大特性是事务的基础，了解了 ACID 是如何实现的，我们也就清楚了事务的实现。



1、OLTP的概述： 联机事务处理过程（On-Line Transaction Processing），也称为面向事物的处理过程。

2、OLAP的概述：联机分析处理（On-Line Analytical Processing）是一种软件技术，它使分析人员能够迅速、一致、交互地从各个方面观察信息，以达到深入理解数据的目的，应用为数据仓库。



大多数业务都需要 OLTP 类型的数据库，InnoDB 在这其中对事物的支持非常好，并发支持的也很好。 通过实现 **Aries** 算法（undo log 、redo log）在崩溃的时候也能保障数据的完整性和一致性。所以选择 InnoDB 作为默认选项。









### **并发事务会引发哪些问题？如何解决？**

脏读，幻读、不可重复读

​       问题描述：                        解决办法

脏读：读到别人回滚的数据，               使用读已提交隔离级别

不可重复读：读到其他事物已经提交的数据    使用可重复读级别，（mvcc机制）

幻读：全部扫描后 ，第二次发现还有新的值没扫描到  mysql （可重复读级别使用 间隙锁 and next-key 锁解决幻读问题），其他数据库使用序列化隔离等级







**InnoBD 和 MyISAM 的区别**



1.Innodb 支持事物，行锁，外键  myisam 只有表锁

2.innodb 是b+ 树 聚簇索引，叶子节点保存一整行数据  myisam 也是b+ 树，但是他非聚簇索引叶子节点保存指针， 数据和索引文件分开存储



3.innodb 物理存储结构就是 表空间文件 + 日志      myisam 分成三个存储文件 1表定义文件， 2 数据文件 3索引文件



4.innodb 查询select 全表扫一遍， myisam 不带where 条件直接查变量



5.innodb 事物支持好， myisam 查询性能高，并且原子的（只有表 共享和排他锁）



其他全文索引、主键啥的目前都差不多了，innodb 也支持 fulltext ，主键规则都差不多，



总体来说，一般 select 更多，可以用myisam ，否则用 innodb







### **主从复制延迟原因**

根本的影响因素：1.slave 拉取 binlog 是单线程的

案例一：主库 dml 请求频繁，短时间造成大量的binlog ，从库速度跟不上

解决：如果是MySQL 5.7以下的版本，可以做分片(sharding)，通过水平扩展(scale out)的方法打散写请求，提升写请求写入binlog的并行度。

 如果是MySQL 5.7以上的版本，在MySQL 5.7，使用了基于组提交(Group Commit)的并行复制。而在MySQL 8.0，使用了基于Write Set的并行复制。这两种方案都能够提升回放binlog的性能，减少延时。



案例二：主库执行大事务

当大事务记录入binlog并同步到从库之后，从库执行这个事务的操作耗时也非常长，这段时间，就会产生主从复制延时。

 举个例子，假如主库花费200s更新了一张大表，在主从库配置相近的情况下，从库也需要花几乎同样的时间更新这张大表，此时从库延时开始堆积，后续的events无法更新。



解决：对于这种情况引起的主从复制延时，我们的改进方法是：拆分大事务语句到若干小事务中，这样能够进行及时提交，减小主从复制延时。



案例三：主库对大表执行**DDL**语句

原因：可能是qps 大，mdl 被ddl 锁住，（master 是多线程的，slave 同步是单线程的），binglog 执行的慢，或者也是类似大事物，从库执行不过来



解决方案：遇到问题可以先通过 show processlist 将阻塞的ddl 语句kill ，然后尽量业务低峰期操作，使用在线ddl 工具



案例四：主库与从库配置不一致

从库性能跟不上



案例五：表缺乏主键或合适索引

全表更新，binlog 产生几十w 条记录



### **主从复制失败如何处理**



1.如果对一致性要求较低，可以继续消费binglog 如果binglog 格式有错误手动修复就可以

**2.**重新同步 步骤 **1.** 锁主库写，**2.**备份主库 **3.**从库取消同步 **4.**从库清空数据，应用备份文件 **5.**重新配置同步





### **在线ddl 工具的使用原理**

旧版本原理：

例子：facebook 的ddl 工具

1. copy 表结构，对新表执行 ddl 语句，然后对旧表加 update\ insert \delete触发器
2. 批量从旧表复制到新表
3. rename （原子性）



缺点：触发器影响性能

优点：rename 不会造成中断执行



新版本原理：

例子 github 的 gh-ost 

1.copy 表结构，对新表执行 ddl 语句

2.起一个线程消费 binlog 

3.批量从旧表复制到新表

4.cut-over  

Cut-over 流程(依赖原理：被 lock table 阻塞后，rename 语句执行优先级 高于 dml 操作)

步骤

1. lock table write
2. 等待binlog 应用完毕
3. Rename 
4. Show processlist 观察 rename 是否执行完毕
5. drop 旧表
6. unlock

结果，dml 被阻塞，但是执行一定是原子性的。 要不就在原表执行，要不就在新表执行，或者是被阻塞

阻塞时间长就放弃了，再重试就行





### **Mysql 两阶段提提交**

https://zhuanlan.zhihu.com/p/343449447 



https://blog.csdn.net/huangjw_806/article/details/100927097

其实所谓的两阶段就是把一个事物分成两个阶段（prepare commit）来提交，主要用于保持 redo log 和 binlog 的一致性。就像下图这样。

![知乎 @授人以渔](/db/知乎 @授人以渔.jpg)

两阶段写日志用意？

为了保证redolog和binlog数据的安全一致性。只有在这两个日志文件逻辑上高度一致了。你才能放心地使用redolog帮你将数据库中的状态恢复成crash之前的状态，使用binlog实现数据备份、恢复、以及主从复制。而两阶段提交的机制可以保证这两个日志文件的逻辑是高度一致的。没有错误、没有冲突。



步骤：

在MySQL内部，在事务提交时利用两阶段提交(内部XA的两阶段提交)很好地解决了上面提到的binlog和redo log的一致性问题：



第一阶段： InnoDB Prepare阶段。此时SQL已经成功执行，并生成事务ID(xid)信息及redo和undo的内存日志。此阶段InnoDB会写事务的redo log，但要注意的是，此时redo log只是记录了事务的所有操作日志，并没有记录提交（commit）日志，因此事务此时的状态为Prepare。此阶段对binlog不会有任何操作。

第二阶段：commit 阶段，这个阶段又分成两个步骤。第一步写binlog（先调用write()将binlog内存日志数据写入文件系统缓存，再调用fsync()将binlog文件系统缓存日志数据永久写入磁盘）；第二步完成事务的提交（commit），此时在redo log中记录此事务的提交日志（增加commit 标签）。





mysql 宕机如何判断事物能回滚还是提交？

不论mysql什么时刻crash，最终是commit还是rollback完全取决于MySQL能不能判断出binlog和redolog在逻辑上是否达成了一致。只要逻辑上达成了一致就可以commit，否则只能rollback。

比如还是上面描述的场景，binlog已经写了，但是MySQL最终选择了回滚。那代表你的binlog比BufferPool（或者Disk）中的真实数据多出一条更新，日后你用这份binlog做数据恢复，是不是结果一定是错误的？



如何判断**binlog**和**redolog**是否达成了一致**#**



当MySQL写完redolog并将它标记为prepare状态时，并且会在redolog中记录一个XID，它全局唯一的标识着这个事务。而当你设置`sync_binlog=1`时，做完了上面第一阶段写redolog后，mysql就会对应binlog并且会直接将其刷新到磁盘中。

下图就是磁盘上的row格式的binlog记录。binlog结束的位置上也有一个XID。

只要这个XID和redolog中记录的XID是一致的，MySQL就会认为binlog和redolog逻辑上一致。就上面的场景来说就会commit，而如果仅仅是rodolog中记录了XID，binlog中没有，MySQL就会RollBack

![L AnETEA COALHAA P BA CCM EOR SUALD Suai MMA Bd Laa n](/db/L AnETEA COALHAA P BA CCM EOR SUALD Suai MMA Bd Laa n.jpg)



**mysql join 操作的底层原理** 

https://www.jianshu.com/p/6086365a73bd?utm_source=tuicool&utm_medium=referral

Nested-Loop Join 算法 （就是两层循环）驱动表在外循环，被驱动表在内循环

1. Simple nested-loop join 算法，没啥优化 A 表每条扫描一遍 B 也扫描一遍
2. index nested-loop join 算法，被驱动表的 join 字段如果有索引，可以尽量减少无效循环次数
3. block nested-loop join 算法，有一个 join buffer 概念，可以将驱动表的数据整块的换粗到缓冲区中，批量的与被驱动表比较。



**myql 连接操作，如何提高性能**



用来进行 join 的字段要加索引，会触发 INLJ 算法，如果是主键的聚簇索引，性能最优。

如果无法使用索引，那么注意调整 join buffer 大小，适当调大些。

小结果集驱动大结果集。用数据量小的表去驱动数据量大的表，这样可以减少内循环个数，也就是被驱动表的扫描次数。

如果 join buffer 足够大，能容下整张表数据，那么无所谓，都可以做驱动表



**cache**可以优化的原因

本质上说，这个效率提高的原因在于提高了从table中获得的每条记录的“利用率”，在使用直观扫描方式时，table的全表扫描只是和一个组合进行匹配，而使用buffer之后则是和cache中的所有组合进行匹配。



左连接 ，右连接，内连接和全外连接的**4**者区别



　　left join （左连接）：返回包括左表中的所有记录和右表中连接字段相等的记录。

　　right join （右连接）：返回包括右表中的所有记录和左表中连接字段相等的记录。

　　inner join （等值连接或者叫内连接）：只返回两个表中连接字段相等的行。

　　full join （全外连接）：返回左右表中所有的记录和左右表中连接字段相等的记录。



**EXPLAIN using_filesort 是什么意思**

https://blog.csdn.net/yangyu112654374/article/details/4251624



是一种比较慢的外部排序，例子：select * from table where t = 1 order by id  ;  这个sql 里的 t 有索引，但是



**InnoBD LRU 缓存算法**



普通LRU 算法在 InnoDB 中的问题：

1.在全表扫描的时候会将所有的真正热数据挤走

2.预读功能也会将一部分非热数据带入缓存中



解决办法：

将 LRU 链表分为两部分，也就是所谓的 old 区 和 yong 区。

yong区：链表的头部，存放经常被访问的数据页，可以理解为热数据

old区：链表尾部，存放不经常被访问的数据页，可以理解为冷数据

这两个部分的交汇处成为 midpoint 

两个区域的比例 通过 innodb_old_blocks_pct 变量控制，默认为old 37% （3/8） yong 73 (5/8)



控制流程：

数据页第一次被加载BufferPool 时在 old 区头部。

当这个数据页在 old 区再次被访问到，会做如下判断

- 如果这个数据也在 LRU 链表 old 区存在的时间超过了 1 秒，就把它移动到 young 区
- 这个存在时间由 innodb_old_blocks_time 变量控制



那怎么解决这些缺点的？

针对原因一

也就是所谓的全表扫描导致Bufferpool中的高频数据页快速被淘汰的问题。

Innodb这么做的:

(1)扫描过程中，需要新插入的数据页，都被放到old区

(2)一个数据页会有多条记录，因此一个数据页会被访问多次

(3)由于是顺序扫描,数据页的第一次被访问和最后一次被访问的时间间隔不会超过1S，因此还是会留在old区

(4)继续扫描，之前的数据页再也不会被访问到，因此也不会被移到young区，最终很快被淘汰

针对原因二

也就是预读到的页，可能不是高频次的页。

你看，你预读到的页，是存在old区的。如果这个页后续不会被继续访问到，是会在old区逐步被淘汰的。因此不会影响young区的热数据。



监控冷热数据 

执行下面命令即可

mysql> show engine innnodb status\G

……

Pages made young 0, not young 0

0.00 youngs/s, 0.00 non-youngs/s

1、数据页从冷到热，称为young；not young就是数据在没有成为热数据情况下就被刷走的量(累计值)。

2、non-youngs/s，这个数值如果很高，一般情况下就是系统存在严重的全表扫描，自然意味着很高的物理读。(上面分析过)

3、youngs/s，如果这个值相对较高，最好增加一个innodb_old_blocks_time，降低innodb_old_blocks_pct，保护热数据。





**Count（\*） 和 count(1) 那个性能更高**

一样高 * 会替换成 0 也就是 count(0) , 都不会扫描字段值。

https://mp.weixin.qq.com/s/foPwJPS8Ek7YmR3ZgV8xMw