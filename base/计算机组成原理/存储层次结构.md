

###### ![image-20200326130727108](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200326130727108.png)



# 存储

存储的最基本单元是一个二进制数字，即二进制位。一位可以存放一个数字 0 或 1。

**问题：为什么现在的计算机都是二进制的？**

**答：人们经常说计算机使用二进制计算是因为它“最有效”。理论上来说，数字信息可以通过区分某些连续物理量的不同值来存储，如电压的高低和电流的大小。要区分的值越多，相邻值的差别就越小，存储器的可靠性就越低。而二进制数仅仅需要区分两个值，于是形成了对数字信息进行编码的最可靠方法。（如果有很久之前有人发明了一种高度可靠的电子设备，可以直接表示10进制，那么现在的计算机就是10 进制了）**

#### 如何编排存储结构

存储器由许多可存放一段信息的单元（或位置）组成，每个单元由一个编号，程序可以通过这个编号来访问这个单元，这个编号就是这个单元的地址。存储器中所有的单元包含的位数相同，而且相邻单元的地址是连续的。

使用二进制数的计算机的存储器也用二进制数表示。

![image-20200323130243288](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200323130243288.png)

（表示 （a） 中的12 个地址，需要4位。（b）（c） 需要3位即可表示）

存储单元最重要的特性是它是最小的可编址单位。近年来，几乎所有的计算机制造商都将存储单元标准化为 8 位，即 8 字节。字节再组成字，32 位字计算机每个字有4个字节，64 位字计算机每个字有 8 个字节。大多数计算机指令都是对字进行操作，如将两个字相加等。也就是说，32 位机器的寄存器位32 位，指令的操作对象位32 位字。

问题二：为什么现在的计算机将每个存储单元标准化位 8 位？

   答：和进制一样，很久之前有存储单元可以由各种各样的位数组成。但是最早的电子计算机只需要存储英文和符号信息（ASCII 码，用 7 bi t 即可表示出全部的语言符号，第一位为0），使用太大的单元会造成浪费。所以从 IDM 的 360 型号机器开始，每个存储单元逐渐统一为 8 位。

#### 字节顺序

每个字中的字节地址可以从左到右或者从右到左编排。前一种情形称为大端派计算机，后一种称为小端派计算机。（计算机界大多数牛逼的设计里都有作者自己的故事，字节顺序的命名可以搜索《格列佛游记》）它影响计算机中数据的传输，如果有字符串，而两台机器恰巧使用不同的存储编排方式就会互相解析不到正确的结果。

# 内存系统的基本构成（用户保存信息的硬件）

### 锁存器、触发器：用于存储一位信息的基本硬件，区别在于锁存器通过电平的高低（高低电平）来触发保存，触发器通过电平从高到低（下降沿）或者从低到高（上升沿）触发保存。

### 寄存器：由锁存器或者出发器组成的实际在计算机中存储机器字的硬件，容量最小（32 bit \64 bit）速度最快。

### 内存：数据的主要存储区域由内存电路组成。

### RAM & ROM ：

### 既可读又可写的内存称为 RAM（即访问存储器。所有的存储器都是随机访问的，叫这个名字是历史原因）。RAM 又可分为静态RAM 和 动态RAM 两大类，静态RAM (SRAM) 由触发器组成。访问速度很快，一般来说是几纳秒。但是不能掉电，被广泛用于二级缓存中。

### 动态 RAM （DRAM）由晶体管和小电容组成的存储单元阵列来存放数据，通过电容的充放电来存放0 和 1 。速度较慢（几十纳秒）。由于存放在电容中的电荷会泄漏，必须在几毫秒内将动态 RAM 中的每一位刷新（重写）一次，以防止数据丢失。刷新需要外部电路来支持。

### 由于动态 RAM 每个存储位仅需要一个晶体管和一个电容，密度高。主存几乎是由动态 RAM 构成的。虽然它速度比较慢，但是可以结合静态RAM 做成高度缓存来发挥各自的特长

#### 具体分类：

最早的存储介质其实是纸片。在第二次工业革命（19 世纪 70 年代）后美国人口遽增，为了完成美国人口普查的要求。霍列瑞斯博士发明了[打孔制表机](https://baike.baidu.com/item/穿孔制表机)。因为其能赚钱又成立了公司，后来他老了以后把公司卖给了下属主管。后面一系列操作成立了 IBM。

![image-20200329164433818](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329164433818.png)

###### 一战过后，德国换装了全新的机械密码机 - 恩尼格玛（当时最强的加密机器）。波兰为了破译德国的密文，发明了炸弹计算机（因为工作声音太大，搞的人心态直接爆炸）

###### ![image-20200329165424935](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329165424935.png)	

后来德国一直升级加密机器，导致破解的难度越来越大，加之德国侵略的意图越来越明显。波兰直接把炸弹计算机和偷来的 恩尼格玛 直接送给了英国以保全自己。然后**图灵**等英国科学家立刻开始着手新一代的破译机。使用电子管作为 CPU 的核心，不久后在 1943 年研发出了世界上第二台电机计算机（第一台是 1942 年美国生产的 ABC 计算机，**不可编程**，仅仅设计用于求解线性方程组）**巨人计算机**。**虽然可编程，但它只为破译密码，所以不算通用计算机。重点在于它就是用纸带作为存储介质的**。但是当时其保密程度堪比核武器，所以十几年后才被世人所知。以至于很多人认为美国的 埃尼阿克 是世界上第一台电子计算机。

后来IBM 为美国研发原子弹设计了 mark I 型机械式计算机，**是最后一款使用纸带的机械计算机**。

##### 易失性内存芯片

* 目前使用的动态 RAM 芯片有几种不同的种类，其中最古老的是FPM （Fast Page Mode，快页型）动态RAM。工作过程是先输入行地址，再输入列地址。通过给内存芯片明确的信号，告诉它何时给出应答。这样，存储器可以和主系统时钟一步工作。

* FPM 型动态 RAM后来逐渐被 EDO（Extended Data output，扩展数据输出）型动态RAM 取代，新型号允许再前一个内存访问周期结束之前启动第二个内存访问周期。这种流水线技术提高了整个内存的带宽，单位时间内可以输出更多的字。

* 再内存芯片访问周期为 12ns 或更慢的时候，FPM 和 EDO 工作的都很好。但随着处理器速度提高，人们对内存芯片的速度提出了更高的要求，他们逐渐被同步动态 RAM （Synchronous DRAM ,SDRAM）所替代。SDRAM 是静态 RAM和动态 RAM 相结合的产物，统一由系统时钟驱动。最大的优点是省去了与内存芯片进行握手的控制信号，而是由 CPU 告诉内存芯片需要运行几个时钟周期，然后启动访问。然后在每个后续的时钟周期中，内存芯片根据它的数据信号的位数，送出 4、8、16 位的数据。省去控制信号而增加了传输速率。

  * 对SDRAM 的改进是双倍数据速率SDRAM （Double Data ，DDR）SDRAM。这种内存芯片可在时钟的上升沿和下降沿均输出数据，使速率提高了一倍。

  ##### 非易失性内存芯片

* RAM 并不是唯一的内存芯片。许多应用中，都要求内存中的程序在断电情况下也能保存。而且，这些数据和程序一旦装入就不会改变。这种需求导致了 ROM 的发展。早期的 ROM 存放的内容只能读取，不能改变或者擦除。ROM 中的数据在生产芯片的时候置入，即通过光感材料在一个包含要装入的数据的存放模式的面罩下曝光，然后将曝光表面蚀刻而成。

* 50 年代，为了提升导弹的威力，需要精确精确制导。想法时把计算机塞进导弹中，让计算机控制导弹轨迹。发射时输入目标即可。但现有的 ROM 都只能在出厂时完成编程，美国人广泛招标。华人周文俊发明了 PROM （Programmable ROM，可编程ROM）。原理是内部包含了许多小熔丝组成的阵列，编程时可以先选定行，再选定列，然后再芯片的特定管脚上加高电平，使选中的熔丝烧断。这样可在使用者手中进行一次编程而不是在出场时就设定好，除此之外与之前的 ROM完全相同。![image-20200329161951620](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329161951620.png)

* 沿着这个方向发展，出现了 EPROM （Erasable PROM，可擦出ROM），不但可以进行一次编程，还可以擦除。在特定的编程器中，当 EPROM 的石英窗口在强紫外光的照射下达到 15 分钟时，它里面的所有位置位1。如果在设计过程中，肯定要发生多次修改的话，它更为经济实用。EROM 一般和静态 RAM 结构相同。

  ![image-20200326133328525](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200326133328525.png)

* 上世纪 60 年代在美俄军备竞赛时期，美国为了完成登月任务（1969 年）研发出了阿波罗制导计算机（AGG），它使用了集成电路和硅芯片，性能和1977 年的苹果 2 相当。但是用什么作为存储介质却是个难题，谁都不敢打保票让PROM 来完成这个任务。而又需要一款完全安静，足够可靠的电子化设备来完成目标。最后NASA 选择了**磁芯记忆体**。一种编织出来的ROM，电线从磁铁芯中纵横穿过，通过铁心磁化的方向，判定 0 和 1。

* ![image-20200329163154176](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329163154176.png)

  ![image-20200329163011207](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329163011207.png)

  一块 ROM 297 字节，AGC 的总容量 72KB。。。。

* 时间回到登月的前一年，intel 公司刚刚成立不久，（刚开始是靠存储起家，做 CPU 才是半路出家的）。但在研究几年内存之后有了意外收获，半导体的工作状况会受到外来电子的干扰。于是 intel 发明了比 EPROM 更好一些的是 EEPROM ，对他进行擦除只需要加上一定的脉冲，擦出操作的难度变小。缺点是，即时最大的 EEPROM 的存储空间一般也只有普通 EPROM  的 1/64，速度也慢了一半。EEPRAM 无法和 DRAM 以及 SRAM 相比，因为它的速度要慢上10倍，容量要小100倍，价格却更高。只适用与对非易失性要求十分高的场合。


* EEPROM的最新类型是**闪存**。闪存可以按块进行擦除和重写。和EEPROM 类似，擦除闪存时并不需要将其从电路中拿出来。当时有很多制造商生产出不超过 1GB 闪存的小印制电路板，用作数码相机的交卷或者其他用途。发展到现在一般手机中的存储器或者电脑上的固态硬盘都是**闪存**

  

![image-20200326140903838](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200326140903838.png)

## 缓存

一直以来，CPU 总是比存储器块。存储器速度的每次升高都伴随着 CPU 速度的增高，彼此保持着差距。实际上，每当有可能在单片芯片上放置更多电路时，CPU 的设计者总是用他们来实现流水线和超标量运算，使CPU 变得更快。存储器的设计者却用这些技术来提高芯片的容量，而不是速度，这就使两者的差别越来越大。这种不平衡的表现就是在 CPU 发出访问存储器的请求后，要经过多个 CPU 周期才能读取到存储器的内容。

如何解决这个问题：

1. 遇到访存指令时，就启动存储器的读动作，然后继续执行后续命令，直到后面指令要用到这些内容的指令再停止。
2. 不让CPU 暂停，要求编译器再读到内容之前不要生成使用该内容的指令。（经常是 LOAD 指令后无事可做，编译器只能插入 NOP（无操作）指令）

上述办法是否可行？如果不可行，应该如何做？

上述两种办法几乎肯定会造成 CPU 的暂停和空跑，对机器性能的影响很大。

实际上，这不是一个技术问题，而是经济问题。工程师完全可以造出和 CPU 一样快的存储器，但代价是要将存储器直接放在芯片内，结果就是CPU 价格升高，或者CPU 占用空间太大。所以，大容量低速存储器和小容量告诉存储器之前作出平衡。

最终，出现了 cache （高速缓存。来自法语 cacher ,意思是隐藏。发音是 cash 。一种小容量高速存储器）。

* 经过工程师无数次的测试评估运行在CPU 中的代码，总结出了一条规律：**局部性原理**
  * 对于操作数据：在单位时间内，CPU 对存储器的访问总是局限在整个存储器中相邻的一小部分中。
  * 对于指令：除分支转移之外的大多数时间，指令都是从相邻的存储单元中取出的。也就是说大多数程序的时间都消耗在了循环当中。

依据上面提出的局部性原理，大可不必将所有的数据与指令都存储在高速存储器（高速缓存）中。只需要将最近一段时间最高概率要执行到的指令和需要使用的数据放到高速存储器（高速缓存）中即可。

![image-20200325205816171](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200325205816171.png)

这样，当在一个短时间片内对一个机器字读写 k 次时， CPU 只需要访问主存一次，另外 k-1 次就可以访问高速缓存了。访问次数越多，总体的性能越好。

把每次访问 cache 直接得到所需数据的情况称为**缓存命中**。为了描述缓存命中的效率，使用**命中率**这个词来描述它。简单的理解，命中率越高，程序所需要耗费在访问内存上的时间越少。

### cache 应该和 CPU 如何配合呢

以局部性原理为指导，把主存和缓存分为固定大小的块。当讨论缓存中的块时，他们通常是指 **cache块（cache line）**。CPU 首先从 ca che 取数据，当没获取到数据的时候（高逼格的说是访问失败），将要访问的字所在的块整体复制到 cache 中。只要运气不太差，很快就会用到该块中的其他字。块越大，相同容量的缓存中的块数越小，额外管理的开销越小。

问题：

1. 缓存和块的大小？

   缓存越大越好但是成本越高。 16K 的高度缓存可以分为1024 块，每块大小为 16B 。也可以分 2048 B，还有其他的分法

2. 指令和数据是共享一个缓存还是分开？

   使用整体缓存设计简单，并能在取指令和取数时间自动平衡。不过当前趋势是分体缓存，也被称为哈佛结构，选择这个方向的动力是 CPU 流水线的广泛应用，在取指单元取指令的同时，取数单元要取数。分体缓存可以支持并行访问。而且指令在程序执行中一般不需要修改，指令缓存中的内容容易写到主存中。

3. 高速缓存的个数？

   目前更倾向于多级缓存，通常在 CPU 中直接封装一个高速缓存，在外面用速度稍慢但容量稍大的存储器作为二级缓存。


## 内存封装及其类型

从半导体存储器诞生起，到 20 世纪 90 年代早期，内存都是以芯片为单位制造、销售和安装。容量 1kb - 1 mb ，但每块芯片都是独立的销售单位。早期 pc 机都有内存插槽，用户在需要扩展内存的时候，可一再插入新的存储器芯片。

现在的办法是将一组芯片（8 或 16 片）一起装在一块印制电路板上出售。根据电路板上的连线时单面还是双面，一般把内存条分为**单面接入内存组件（Single inline memory module,SIMM，32 位）**和**双面接入内存组件（Dual inline memory moudle,DIMM，64 位）**

多数计算机上提供插入 4 条内存条的空间。笔记本上的 DIMM 体积比较小，叫做小型 **DIMM（small outline dimm,SO-DIMM）。**

首先讲到内存，许多用户都知道DDR3，DDR4这些但是对于DIMM和SDRAM却不太了解。这里面有一个区别，DIMM是指针脚插槽，也就是物理结构方面的分类；而SDRAM和DDR都是内部技术方面的分类。

![image-20200329155748787](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329155748787.png)

SDRAM:Synchronous Dynamic Random Access Memory，同步动态随机存储器。而DDR（Double Data Rate）系列，严格意义上讲，应该是Double Data Rate SDRAM内存，也就是和说在SDRAM基础上改进的版本，只不过日常生活中，通常被简略的直接称作DDR内存。而无论是SDRAM还是DDR，实际上都是DIMM内存。

![image-20200329154831987](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329154831987.png)

## 三星 LPDDR5 DRAM (**Low-Power Double Data Rate Synchronous Dynamic Random Access Memory 通常缩写为“ **低功耗DDR SDRAM**或**LPDDR SDRAM”**，是一种[双倍数据速率](https://en.wikipedia.org/wiki/Double_data_rate) [同步动态随机存取存储器](https://en.wikipedia.org/wiki/Synchronous_dynamic_random-access_memory)，其功耗较低，是[移动计算机的](https://en.wikipedia.org/wiki/Mobile_computer)目标。它也称为**移动DDR**，缩写为**mDDR**。**)

###### ![image-20200402100756897](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200402100756897.png)

16GB LPDDR5 的数据传输速率为 5,500 兆比特/秒 (Mb/s)，比以前的移动内存 （LPDDR4X， 4266Mb/s） 快约 1.3 倍。与 8GB LPDDR4X 封装相比，新型移动 DRAM 可节省 20% 以上的能源，同时提供高达两倍的容量

三星的 16GB LPDDR5 移动 DRAM 封装由 8 个 12 千兆字节 (GB) 芯片和 4 个 8Gb 芯片组成，为高级智能手机配备了两倍于当今许多高端笔记本电脑和游戏个人计算机的 DRAM 容量。除了超快的性能外，大容量支持动态和响应式游戏以及高级智能手机上的超高分辨率图形，提供高度沉浸式移动游戏体验。

## 三星 HBM2E Flashbolt

![image-20200402101658608](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200402101658608.png)

### 了解 HBM



HBM 的意思是“高带宽内存”，这是用于 3D 堆叠 SDRAM（同步动态随机存取内存）的高性能接口。与其他动态随机存取存储器 (DRAM) 解决方案相比，它以较小的外形可提供更快的数据传输速率，功耗更低，总线范围（应该是说寻址）更广。对于高性能计算应用、计划利用 AI 的行业、显卡供应商和高级网络应用程序，HBM 提供数据速度提升，这对于推动行业向前发展十分重要。

三星在推出 HBM 内存解决方案的同时还引入了 HBM2 和 HBM2E，允许每个堆栈使用更多的 DRAM 晶片，从而全面增加容量。例如，在该公司的第二代 HBM Aquabolt 产品中，三星 HBM2E Flashbolt 提供 1.3 倍带宽，且每针数据传输速度比上一代 HBM2 解决方案快 33%。



### 紧凑包装中的下一级速度和容量

#### 

Flashbolt 是一款第三代 16GB HBM2E 产品。它提供更高级别的规格，通过垂直堆叠八层 10 纳米 (nm) 级 16 千兆比特 (Gb) DRAM 晶片，能够提供高达 410 千兆比特/秒 (GB/s) 的卓越内存带宽级别和每引脚 3.2 GB/s 的数据传输速度。为具体说明 Flashbolt 的速度，该解决方案可以实现以每秒 3.2 千兆位每秒的传输速度传输 82 部全高清电影（410 GB 数据）。 如此之快的速度意味着 Flashbolt 处于理想的位置，可以最大限度地发挥下一级图形系统向前发展的能力。此外，Flashbolt 的容量是其前身 HBM2 Aquabolt 的两倍，其采用紧凑、节能的格式，非常适合空间有限的设计。

# 辅存

上面介绍了计算机的内存结构，但无法存储大量数据。

问题：如何存储大量的数据？

使用下图的存储层次结构

- 第一层：最快，速度可以满足CPU 的要求
- 第二层：目前容量在32 kb 到几兆字节。
- 第三层：从 16MB 到几十G
- 第四层：永久存放数据的主要介质
- 第五层：用于后备存储

从上至下，有三个参数主键增大。

1. 访问时间增大
2. 存储容量逐渐增大
3. 单位存储量的价格变低

![image-20200329160142297](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329160142297.png)

## 磁盘

### 磁盘历史

磁盘或者说机械硬盘的发明 IBM 居功甚伟，但这里先介绍磁盘的祖宗**磁鼓（1932 、奥地利发明）**。![image-20200329172311545](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329172311545.png)

一个桶，在高速旋转过程中，信息可以通过其外侧读取或者写入（转速 12500 估计运作起来嗡嗡的）。它是和打孔卡一起工作的，因为断电后不能保存信息，所以它算是一款 RAM。

IBM 把它商用在自己的计算机上，但是它的价格太贵，制造太难，容量太小。所以 50 年代商用了两年就被市场抛弃，改为纵向的盘片所取代了。

![image-20200329172722722](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329172722722.png)

后来，由于 IBM 需要寻找一种可以断电不丢失信息并且可以替换打孔卡的存储介质，提出了磁带的解决方案。在当时速度快，性能好，但是它要倒带。。最终的结局是连磁鼓都没取代。

重金之下 IBM 在 1956 年造出了世界上第一款机械硬盘：IBM 350 （重达 1 吨，用机械轴承驱动。由 50 块 24 英寸的超大盘片组成，每个硬盘只有100 个扇区、100 个圆轨道、转速 1200。容量总共5 MB ）原理是用两个探头（一读，一写）集成在一起对盘片分别进行读写操作，甚至为了防止读写操作把数据弄混，要在不同的盘上进行读写。它又大又贵又爱坏（平均寿命 2000 h）,探头还容易直接和盘面接触，刮坏盘面。

![image-20200329174232348](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329174232348.png)

下一个里程碑式 1961 年的 1301 硬盘，最大的进步是所有的盘片都有独立的磁头和机械臂。通过空气动力学设计，磁头可以在运行时漂浮在盘面上。机械轴承页替换成了空气轴承，容量 28 MB。

1963 年 1311 硬盘问世，机器体积缩小到一台洗衣机大小，并且受到磁带的影响，被设计成了可更换的硬盘包。

![image-20200329174909645](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329174909645.png)

![image-20200329172111647](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329174954838.png)

整个 60 年代，随着集成电路和晶体管技术的大范围普及小型化和廉价化逐渐成为了市场方向。到 1973 年IBM 成功研制出一种新型的硬盘 IBM 334。这种硬盘拥有几个同轴的金属盘片，盘片上涂着磁性材料。它们和可以移动的磁头共同密封在一个盒子里面，磁头能从旋转的盘片上读出磁信号的变化--这就是我们今天使用的硬盘的祖先，IBM把它叫做温彻斯特硬盘。

![image-20200329175423959](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329175423959.png)

之后的1979 年，希捷公司上架了世界上第一款 5.25 寸硬盘，价格 1500 美刀，容量 5MB。

后来的机械硬盘一小再小，记录2001 年诺基亚n91 放在手机中的特制机械硬盘，0.85 寸，东芝出品。

![image-20200329180108585](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329180108585.png)

![image-20200329180137283](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329180137283.png)

## 机械硬盘（磁盘）的原理

现代机械硬盘由 磁盘、磁头、磁头臂、用磁铁，音圈马达，主轴构成。一个机械硬盘里面可以有几张磁盘叠加在一起。每个盘面均有一个对应的磁头。

![image-20200329182120649](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329182120649.png)

磁盘的上含有引导线圈的刺头正好漂浮于磁盘表面 3 nm 处，当磁头中有正或负电流通过时，就可以磁化磁头正下方的磁盘表面，根据驱动电流的极性不同，使磁性颗粒从左朝右偏转。读取数据时，磁头通过磁性区域，将被感应出正负电流。

​	所有的磁盘都有一个能从磁盘旋转的轴心伸缩道不同半径的磁臂，可以伸展不同的半径。磁盘旋转一周后通过磁头写入磁盘的数据位形成的环道称为**磁道**。每个磁道可以化为位固定长度的扇区，每个扇区一般有存放 512 字节的**数据区域**，**数据区**前有用于再读写之前对磁头进行同步的**前导区**，数据区之后时纠错码。连续两个扇区之前有**隔离带**。![image-20200329181302025](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329181302025.png)

![image-20200329180739673](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329180739673.png)

磁道的宽度取决于磁头的大小和磁臂的伸缩精度。现有精度（可能十好几年前了）下，每厘米磁盘可以有 5000～ 10000 个磁道，磁道宽度为 1-2 微米。磁道在物理上并不是磁盘表面的凹槽，只是简单地由磁性材料组成的圆环，中间有隔离区将相邻的磁道隔开。

磁道环上的位密度主要取决于磁表面的纯度和空气质量。目前磁盘能达到的密度是 5 ~ 10 w 位/cm。为了获得更高的磁密度，可以使存储一位信息的磁颗粒的“长”的方向不在随磁道方向，而是垂直于磁道，深入到铁氧化物中。这项技术就是“垂直记录”

![image-20200329184213460](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329184213460.png)

已经说过机械硬盘都是由许多磁盘叠在一起的，每个磁盘表面都有自己的磁头和磁臂，所有的磁臂链接在一起，因此他们同时指向同一轴向位置。把位于同一半径的磁道集合称为**柱面**。

![image-20200329184628046](https://github.com/TransientWang/KnowledgeBase/blob/master/picture/计算机组成原理/image-20200329184628046.png)



与磁盘驱动器相连的是控制它的芯片 - **磁盘控制器**，有些控制器中甚至有一个完全的 CPU。控制器的任务包括接受软件发出的如 RWEAD、WRITE、和FORMAT（往磁盘中写入所有引导区）等命令、控制磁盘臂的运动，发现和纠正错误，将从内存中读来的8位字节转换成位串写到磁盘中，或者做相反的操作。还有些控制器可以对多个扇区进行缓冲，缓存一些扇区的内容以备降来使用，还可以重新影响坏扇区。最后的功能是由于坏扇区（被永磁化）而加上的。当控制器发现坏扇区时，可以用预留在每个柱面或区域的一个空白扇区替换它。